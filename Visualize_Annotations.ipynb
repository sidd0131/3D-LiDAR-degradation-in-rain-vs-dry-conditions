{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c2514b4",
   "metadata": {},
   "source": [
    "## Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "457aaa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de05341",
   "metadata": {},
   "source": [
    "## Vizualize one data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3540ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to sample:\n",
    "Kitti_file='/media/i2r/My Passport/KITTI/object/sampledata/velodyne/000000.bin'\n",
    "annotation_file='/media/i2r/My Passport/KITTI/object/sampledata/label_2/000000.txt'\n",
    "calibration_file='/media/i2r/My Passport/KITTI/object/sampledata/calib/000000.txt'\n",
    "# Load binary point cloud\n",
    "bin_pcd = np.fromfile(Kitti_file, dtype=np.float32)\n",
    "point_cloud_range = [0, -39.68, -3, 69.12, 39.68, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "deb3d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape and drop intensity values\n",
    "points = bin_pcd.reshape((-1, 4))[:, 0:4]\n",
    "np_pcd=[]\n",
    "for point in points:\n",
    "    if point[1]>-39.68 and point[1]<39.68:\n",
    "        if point[0]>0 and point[0]<69.12:\n",
    "            if point[2]>-3 and point[2]<1:\n",
    "                np_pcd.append(list(point[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "737c1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_pcd = np.asarray(np_pcd)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np_pcd)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f2e9d",
   "metadata": {},
   "source": [
    "## Read annotation file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d148e8f",
   "metadata": {},
   "source": [
    "### Some relevant functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf9c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h- height, w - width, l - length, x,y,z - locations of center and yaw is rotation around Y axis; \n",
    "#more details here: https://docs.nvidia.com/tao/tao-toolkit/text/data_annotation_format.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d70ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the annotation file\n",
    "def read_annotation_file(annotation_file):\n",
    "    annotations = []\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "          #Ped for pedestrian, Car for car etc.\n",
    "          if line[0:3]=='Ped':\n",
    "            data = line.strip().split(' ')\n",
    "            # Extract the relevant information from the line\n",
    "            h, w, l, x, y, z, yaw = map(float, data[8:15])\n",
    "            annotation = [h, w, l, x, y, z, yaw]\n",
    "            annotations.append(annotation)\n",
    "    return annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf61d9",
   "metadata": {},
   "source": [
    "These functions are not important for you to spend time on. Just know that the annotations in Kitti are in camera coordinates and these functions are used to turn them into LiDAR coordinates - to work with the data and visualize it easier. You can simply ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b93681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roty(t):\n",
    "    \"\"\" Rotation about the y-axis. \"\"\"\n",
    "    c = np.cos(t)\n",
    "    s = np.sin(t)\n",
    "    return np.array([[c, 0, s], [0, 1, 0], [-s, 0, c]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1700385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_rect_to_velo( pts_3d_rect):\n",
    "        \"\"\" Input: nx3 points in rect camera coord.\n",
    "            Output: nx3 points in velodyne coord.\n",
    "        \"\"\"\n",
    "        pts_3d_ref = project_rect_to_ref(pts_3d_rect)\n",
    "        return project_ref_to_velo(pts_3d_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7537673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_rect_to_ref(pts_3d_rect):\n",
    "        \"\"\" Input and Output are nx3 points \"\"\"\n",
    "        return np.transpose(np.dot(np.linalg.inv(R0), np.transpose(pts_3d_rect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c609ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_calib_file( filepath):\n",
    "        \"\"\" Read in a calibration file and parse into a dictionary.\n",
    "        Ref: https://github.com/utiasSTARS/pykitti/blob/master/pykitti/utils.py\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        with open(filepath, \"r\") as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.rstrip()\n",
    "                if len(line) == 0:\n",
    "                    continue\n",
    "                key, value = line.split(\":\", 1)\n",
    "                # The only non-float values in these files are dates, which\n",
    "                # we don't care about anyway\n",
    "                try:\n",
    "                    data[key] = np.array([float(x) for x in value.split()])\n",
    "                except ValueError:\n",
    "                    pass\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a233ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_rigid_trans(Tr):\n",
    "    \"\"\" Inverse a rigid body transform matrix (3x4 as [R|t])\n",
    "        [R'|-R't; 0|1]\n",
    "    \"\"\"\n",
    "    inv_Tr = np.zeros_like(Tr)  # 3x4\n",
    "    inv_Tr[0:3, 0:3] = np.transpose(Tr[0:3, 0:3])\n",
    "    inv_Tr[0:3, 3] = np.dot(-np.transpose(Tr[0:3, 0:3]), Tr[0:3, 3])\n",
    "    return inv_Tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9149251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_ref_to_velo( pts_3d_ref):\n",
    "    pts_3d_ref = cart2hom(pts_3d_ref)  # nx4\n",
    "    return np.dot(pts_3d_ref, np.transpose(C2V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf6235fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cart2hom(pts_3d):\n",
    "    \"\"\" Input: nx3 points in Cartesian\n",
    "            Oupput: nx4 points in Homogeneous by pending 1\n",
    "    \"\"\"\n",
    "    n = pts_3d.shape[0]\n",
    "    pts_3d_hom = np.hstack((pts_3d, np.ones((n, 1))))\n",
    "    return pts_3d_hom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acad0079",
   "metadata": {},
   "source": [
    "### This function is to obtain the 8 corners of the annotation box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d10cbd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_box_3d(annotation, P):\n",
    "    \"\"\" Takes an object and a projection matrix (P) and projects the 3d\n",
    "        bounding box into the image plane.\n",
    "        Returns:\n",
    "            corners_2d: (8,2) array in left image coord.\n",
    "            corners_3d: (8,3) array in in rect camera coord.\n",
    "    \"\"\"\n",
    "    # compute rotational matrix around yaw axis\n",
    "    R = roty(annotation[6])\n",
    "\n",
    "    # 3d bounding box dimensions\n",
    "    l = annotation[2]\n",
    "    w = annotation[1]\n",
    "    h = annotation[0]\n",
    "\n",
    "    # 3d bounding box corners\n",
    "    x_corners = [l / 2, l / 2, -l / 2, -l / 2, l / 2, l / 2, -l / 2, -l / 2]\n",
    "    y_corners = [0, 0, 0, 0, -h, -h, -h, -h]\n",
    "    z_corners = [w / 2, -w / 2, -w / 2, w / 2, w / 2, -w / 2, -w / 2, w / 2]\n",
    "\n",
    "    # rotate and translate 3d bounding box\n",
    "    corners_3d = np.dot(R, np.vstack([x_corners, y_corners, z_corners]))\n",
    "    # print corners_3d.shape\n",
    "    corners_3d[0, :] = corners_3d[0, :] + annotation[3]\n",
    "    corners_3d[1, :] = corners_3d[1, :] + annotation[4]\n",
    "    corners_3d[2, :] = corners_3d[2, :] + annotation[5]\n",
    "    return np.transpose(corners_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c817f2d",
   "metadata": {},
   "source": [
    "### Get the annotation and calibration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8abbfaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = read_annotation_file(annotation_file)\n",
    "calibs = read_calib_file(calibration_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ca660",
   "metadata": {},
   "source": [
    "### Apply the necessary transformations to get the LiDAR coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de66187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "R0 = calibs[\"R0_rect\"]\n",
    "R0 = np.reshape(R0, [3, 3])\n",
    "V2C = calibs[\"Tr_velo_to_cam\"]\n",
    "V2C = np.reshape(V2C, [3, 4])\n",
    "C2V = inverse_rigid_trans(V2C)\n",
    "P = calibs[\"P2\"]\n",
    "P = np.reshape(P, [3, 4])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4c7242",
   "metadata": {},
   "source": [
    "### Obtain the box coordinates of the annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71f0872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annots=[]\n",
    "for annotation in annotations:\n",
    "    box3d_pts_3d = compute_box_3d(annotation, P)\n",
    "    pts_3d_ref=np.transpose(np.dot(np.linalg.inv(R0), np.transpose(box3d_pts_3d)))\n",
    "    pts_3d_ref = cart2hom(pts_3d_ref) \n",
    "    box3d_pts_3d_velo=np.dot(pts_3d_ref, np.transpose(C2V))\n",
    "    annots.append(box3d_pts_3d_velo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4169fa",
   "metadata": {},
   "source": [
    "### Draw the box in 3D and vizualize it on the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2ed210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_sets=[]\n",
    "# Our lines span from points 0 to 1, 1 to 2, 2 to 3, etc...\n",
    "lines = [[0, 1], [1, 2], [2, 3], [0, 3],\n",
    "         [4, 5], [5, 6], [6, 7], [4, 7],\n",
    "         [0, 4], [1, 5], [2, 6], [3, 7]]\n",
    "\n",
    "# Use the same color for all lines\n",
    "colors = [[1, 0, 0] for _ in range(len(lines))]\n",
    "line_set = o3d.geometry.LineSet()\n",
    "line_set.points = o3d.utility.Vector3dVector(box3d_pts_3d_velo)\n",
    "line_set.lines = o3d.utility.Vector2iVector(lines)\n",
    "line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "\n",
    "#Visualize\n",
    "o3d.visualization.draw_geometries([line_set,pcd])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
